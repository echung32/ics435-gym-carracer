{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHyN/5+BqI572tsf6/o7vH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ics435/CNN_CarRacer/blob/main/CNN_CarRacer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwRj3ZATBnBf"
      },
      "source": [
        "# OpenAI CarRacing with Behavioral Cloning\n",
        "\n",
        "In this homework, you will train an agent to drive on a race track in a video-game style simulator. The agent has a neural network controller that you will train using example data of a car racing around the track. At each timestep, the neural network takes in the *state* of the car as an image and outputs which *action* to take.\n",
        "\n",
        "This system is known as a *Markov Decision Process (MDP)* because at each discrete timestep, the agent makes a decision using only the current state, with no memory of the previous state (this is called the Markov property). In the context of Reinforcement Learning, this training strategy is known as *behavioral cloning* because we are learning by copying the actions of another agent.\n",
        "\n",
        "The simulator is the CarRacing-v0 environment from OpenAI. In this environment, a *state* is a (96, 96, 3) color image which shows the position of the car along with the current speed, stearing position, and braking status in the bottom of the image. The *actions* that are available to the agent are stear (between -1 and 1), accelerate (0 to 1), and break (0 to 1). To simplify this assignment, I have converted this into a classification problem with only seven discrete actions:\n",
        "\n",
        "0. Do nothing\n",
        "1. Left\n",
        "2. Left+Break\n",
        "3. Right\n",
        "4. Right+Break\n",
        "5. Accelerate!\n",
        "6. Break\n",
        "\n",
        "Below is provided a dataset of 11,132 example (state, action) pairs you can use for training. These were sampled from simulations of a highly-skilled AI agent. The first cell downloads the data and installs many of the dependencies needed to run the simulations and generate videos in Google Colab. You should be able to train your agent and view videos of your agent within Colab.\n",
        "\n",
        "## Tasks:\n",
        "1.   Create a class called `Agent` with methods 'train' and 'act'.\n",
        "2.   Train the agent to drive. Optimize hyperparameters such as the learning rate, network architecture, etc. You can do this by hand (you don't need to do anything fancy).\n",
        "3. Create a video of your agent driving.\n",
        "\n",
        "## To turn in:\n",
        "1. Your code as a jupyter notebook.\n",
        "2. A description of your agent model and its performance. Include this description after your code in the jupyter notebook, following the [Guide to Describing ML Methods](https://laulima.hawaii.edu/access/content/group/MAN.XLSIDIN35ps.202230/Guide_to_Describing_ML_Methods.pdf). I don't expect you to do extensive hyperparameter tuning, but you **must** describe the performance of your model on a validation set using the appropriate metrics so that you know when you are overfitting.\n",
        "3. Upload a video of your best agent to [this google drive](https://drive.google.com/drive/folders/1Hk4PTqfr5A3BeW2m3mgAuQmbxo_Z-8AK?usp=sharing). (Feel free to also upload any funny or interesting behavior.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "0WycAuNU2JX1",
        "outputId": "4c0cfc74-f4e6-41a8-b22b-6d9d1e42de8f"
      },
      "source": [
        "# NO NEED TO MODIFY THIS CELL\n",
        "# First install dependencies for rendering openai gym in colab and recording.\n",
        "# Remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install swig > /dev/null 2>&1\n",
        "!pip install gym[box2d] pyvirtualdisplay piglet > /dev/null 2>&1\n",
        "!apt install -y xvfb  > /dev/null 2>&1\n",
        "!apt install -y python-opengl ffmpeg > /dev/null 2>&1\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "gymlogger.set_level(40) #error only\n",
        "from gym.wrappers.record_video import RecordVideo\n",
        "import numpy as np\n",
        "import random, math, glob, io, base64\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else:\n",
        "    print(\"Could not find video\")\n",
        "\n",
        "def wrap_env(env):\n",
        "  \"\"\"\n",
        "  Utility functions to enable video recording of gym environment and displaying it\n",
        "  To enable video, just do \"env = wrap_env(env)\"\"\n",
        "  \"\"\"\n",
        "  env = RecordVideo(env, './video',  episode_trigger = lambda episode_number: True)\n",
        "  # Monitor(env, './video', force=True)\n",
        "  env.reset()\n",
        "  return env\n",
        "\n",
        "# Download example data for training.\n",
        "import gzip, os, pickle, random\n",
        "import matplotlib.pyplot as plt\n",
        "!gdown --id 1AQnMFSRU3qQcHA-ruS8Ahcz-00FmYoi0 # File shared on Peter's gdrive 6MB.\n",
        "with gzip.open('carracing_behavior.gzip', 'rb') as f:\n",
        "    states, action_classes = pickle.load(f)\n",
        "\n",
        "print('\\nState data shape (examples, x, y, color):', states.shape)\n",
        "print('Action data shape (examples, action idx):', action_classes.shape)\n",
        "\n",
        "# Plot an example state. This is the model input.\n",
        "print('\\nExample state (this is the input to your neural network):')\n",
        "plt.imshow(states[0, :, :, :])\n",
        "\n",
        "# The simulator expects a length-3 array corresponding to stear,\n",
        "# accellerate, and break. But I converted the training data actions into a\n",
        "# discrete set to frame the problem as classification. This is the set of\n",
        "# possible actions. The indices in training data targets (action_classes)\n",
        "# correspond to this set of actions. Your agent's act method should\n",
        "# return one of these, not an integer index.\n",
        "ACTION_SPACE = [[0, 0, 0],  # no action\n",
        "                [-1, 0, 0],  # left\n",
        "                [-1, 0, 1],  # left+break\n",
        "                [1, 0, 0],  # right\n",
        "                [1, 0, 1],  # right+break\n",
        "                [0, 1, 0],  # acceleration\n",
        "                [0, 0, 1], ]  # break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AQnMFSRU3qQcHA-ruS8Ahcz-00FmYoi0\n",
            "To: /content/carracing_behavior.gzip\n",
            "100% 6.57M/6.57M [00:00<00:00, 19.7MB/s]\n",
            "\n",
            "State data shape (examples, x, y, color): (11132, 96, 96, 3)\n",
            "Action data shape (examples, action idx): (11132,)\n",
            "\n",
            "Example state (this is the input to your neural network):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSG302fDI7JC"
      },
      "source": [
        "# Create, Train, and Simulate Agent\n",
        "\n",
        "Create your agent class below. The code provided should help get you started. Then test your agent in the racing environment.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2dMCVu7JVWc"
      },
      "source": [
        "# WRITE CODE HERE\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "class Agent():\n",
        "  def __init__(self):\n",
        "    self.action_space = ACTION_SPACE\n",
        "\n",
        "  def train(self, X, Y):\n",
        "    \"\"\"\n",
        "    Defines an object self.model with method predict that takes input image and\n",
        "    outputs a vector of probabilities over ACTION_SPACE. This model can be\n",
        "    defined using any package (suggested: keras or pytorch).\n",
        "    \"\"\"\n",
        "    # WRITE ME\n",
        "    pass\n",
        "\n",
        "  def act(self, state):\n",
        "    \"\"\"Choose action to take in this state.\n",
        "    Args:\n",
        "      state: np.array of shape (96, 96, 3)\n",
        "    \"\"\"\n",
        "    # model.predict expects batch dimension along first axis.\n",
        "    state = np.expand_dims(state, axis=0)\n",
        "    act_values = self.model.predict(state, verbose=0)\n",
        "    action_index = np.argmax(act_values[0])\n",
        "    return self.action_space[action_index]\n",
        "\n",
        "agent = Agent()\n",
        "actions_onehot = to_categorical(action_classes)\n",
        "agent.train(states, actions_onehot)\n",
        "agent.model.save('agent.h5') # Can be reloaded from file.\n",
        "#agent.model = load_model('agent.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLj3USuFM6Lf"
      },
      "source": [
        "# NO NEED TO MODIFY THIS CELL\n",
        "# Run simulation for t timesteps.\n",
        "from tqdm import tqdm\n",
        "NUM_TIMESTEPS = 2000  # Increase this to run simulation longer.\n",
        "with wrap_env(gym.make(\"CarRacing-v2\")) as env: # Exits env when done.\n",
        "  observation = env.reset()  # Restarts car at the starting line.\n",
        "  for t in tqdm(range(NUM_TIMESTEPS)):\n",
        "    env.render()\n",
        "    action = agent.act(observation)\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "      print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "      break\n",
        "show_video()  # Video can be downloaded by clicking option in bottom right."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}